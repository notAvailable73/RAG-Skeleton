{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798d4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import glob\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66556389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_credentials():\n",
    "    if \"GROQ_API_KEY\" not in os.environ:\n",
    "        print(\"GROQ_API_KEY not found\") \n",
    "    if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "        print(\"GOOGLE_API_KEY not found\") \n",
    " \n",
    "check_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c44727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pdf(path: str):\n",
    "    print(f\"Loading PDF from: {path}\")\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()  \n",
    "def load_pdf_from_dir(directory_path: str):\n",
    "    all_docs = [] \n",
    "    pdf_files = glob.glob(os.path.join(directory_path, \"*.pdf\"))\n",
    "    \n",
    "    for pdf_path in pdf_files: \n",
    "        doc = load_pdf(pdf_path)\n",
    "        all_docs.append(doc)\n",
    "        \n",
    "    return all_docs\n",
    "def split_documents(docs, chunk_size=1000, chunk_overlap=150):\n",
    "    print(f\"Splitting documents into chunks of size {chunk_size} with overlap {chunk_overlap}\")\n",
    "     \n",
    "    flattened_docs = [doc for sublist in docs for doc in sublist]\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap\n",
    "    ) \n",
    "    return splitter.split_documents(flattened_docs)\n",
    "\n",
    "\n",
    "def build_vectorstore(splits):\n",
    "    print(\"Building vector store\")\n",
    "    emb = HuggingFaceEmbeddings(model_name=\"ibm-granite/granite-embedding-30m-english\")\n",
    "    return FAISS.from_documents(splits, emb)\n",
    "\n",
    "def setup_pipeline(dir_path: str, chunk_size=1000, chunk_overlap=150):\n",
    "    print(\"Setting up the RAG pipeline\")\n",
    "    docs = load_pdf_from_dir(dir_path)\n",
    "    splits = split_documents(docs, chunk_size, chunk_overlap)\n",
    "    vs = build_vectorstore(splits)\n",
    "    return vs\n",
    "\n",
    "def format_docs(docs): \n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1cf4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\", \n",
    ")  \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer ONLY from the provided context. If not found, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04e36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query(vectorstore, question: str): \n",
    "    \n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "    parallel = RunnableParallel({\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    })\n",
    "\n",
    "    chain = parallel | prompt | llm | StrOutputParser()\n",
    " \n",
    "    return chain.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6644641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the RAG pipeline\n",
      "Loading PDF from: ./docs/bukhari.pdf\n",
      "Loading PDF from: ./docs/book1.pdf\n",
      "Splitting documents into chunks of size 1000 with overlap 150\n",
      "Building vector store\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"./docs\"  \n",
    "vectorstore = setup_pipeline(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe9bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Driven Architecture (EDA) is an architecture style that reverses the tightly coupled synchronous calls between services, instead decoupling systems in time and allowing them to evolve independently of one another. This approach uses events to make the system pluggable and to transfer state between systems.\n"
     ]
    }
   ],
   "source": [
    "ques= \"What is Event Driven Architecture?\"\n",
    "ans = query(vectorstore, ques)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e94e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imaam Bukhari was a scholar of Hadith and the compiler of the book \"Sahih Bukhari\", a collection of authentic Hadiths of the Holy Prophet Muhammad.\n"
     ]
    }
   ],
   "source": [
    "ques= \"Who is imaam bukhari\"\n",
    "ans = query(vectorstore, ques)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
